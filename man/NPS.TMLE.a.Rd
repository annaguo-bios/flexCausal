% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NPS-TMLE-a.R
\name{NPS.TMLE.a}
\alias{NPS.TMLE.a}
\title{Estimate average counterfactual outcome E(Y(a)).}
\usage{
NPS.TMLE.a(
  a = NULL,
  data = NULL,
  vertices = NULL,
  di_edges = NULL,
  bi_edges = NULL,
  treatment = NULL,
  outcome = NULL,
  multivariate.variables = NULL,
  graph = NULL,
  superlearner.seq = F,
  superlearner.Y = F,
  superlearner.A = F,
  superlearner.M = F,
  superlearner.L = F,
  crossfit = F,
  K = 5,
  ratio.method.L = "bayes",
  ratio.method.M = "bayes",
  dnorm.formula.M = NULL,
  dnorm.formula.L = NULL,
  lib.seq = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.L = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.M = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.Y = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.A = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  formulaY = "Y ~ .",
  formulaA = "A ~ .",
  linkY_binary = "logit",
  linkA = "logit",
  n.iter = 500,
  cvg.criteria = 0.01,
  truncate_lower = 0,
  truncate_upper = 1,
  zerodiv.avoid = 0
)
}
\arguments{
\item{a}{Treatment level or a length two vector specifying treatment levels.
The average counterfactual outcome(s) will be computed at the specified treatment level(s).
If \code{a} is a single value, the function will return \code{E(Y(a))}, which is the
average counterfactual outcome under the treatment level specified by \code{a}.
If \code{a} is a vector of length two, say \code{c(value1, value2)}, the function will return
\code{E(Y(a=value1)) - E(Y(a=value2))}, which is the contrast between the average
counterfactual outcomes under the two specified treatment levels.}

\item{data}{A Dataframe contains all the variables listed in vertices parameter}

\item{vertices}{A vector of variable names in the causal graph}

\item{di_edges}{A list of directed edges in the causal graph. For example, \code{di_edges=list(c('A','B'))} means there is a directed edge from vertex A to B.}

\item{bi_edges}{A list of bidirected edges in the causal graph. For example, \code{bi_edges=list(c('A','B'))} means there is a bidirected edge between vertex A and B.}

\item{treatment}{A character string indicating the treatment variable}

\item{outcome}{A character string indicating the outcome variable}

\item{multivariate.variables}{A list of variables that are multivariate in the causal graph. For example, \verb{multivariate.variables=list(M=c('M1,'M2'))} means M is bivariate and the corresponding columns in the dataframe are M1 and M2.}

\item{graph}{A graph object generated by the \code{make.graph()} function. User only need to specify either \code{graph} or \code{vertices}, \code{di_edges}, \code{bi_edges}, and \code{multivariate.variables}.}

\item{superlearner.seq}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted when performing sequential regression to estimate the conditional expectations as the nuisances consititute the efficient influence function.}

\item{superlearner.Y}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the outcome regression.}

\item{superlearner.A}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the propensity score.}

\item{superlearner.M}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set M when \code{ratio.method.M="bayes"}.}

\item{superlearner.L}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set L when \code{ratio.method.L="bayes"}.}

\item{crossfit}{A logical indicator determines whether crossfitting is adopted for SuperLearner. If crossfit is set to TRUE, the data is split into K folds as specified by the \code{K} parameter.}

\item{K}{An integer specifying the number of folds for crossfitting.}

\item{ratio.method.L}{A character string indicating the method used to estimate the density ratio associated with L. There are three options: 'bayes', 'dnorm', and 'densratio'.
The default is 'bayes'. The \code{bayes} method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by rewriting it as \eqn{(p(a0|L,...)/p(a1|L,...))/(p(a0|...)/p(a1|...))}.
Here \eqn{p(a0|L,...)} and \eqn{p(a0|...)} are estimated via linear regression if \code{superlearner.L=F} and via superlearner if \code{superlearner.L=T}.
The \code{dnorm} method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by assuming that the density of L given A is normal if L is continuous. And assume L|...,A can be modeled via logistic regression if L is binary.
The \code{densratio} method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by using the \code{densratio} function in the \link[densratio]{densratio} package. The \code{densratio} method is computationally expensive compared to the other two methods.
Therefore, if there is a large number of variables in your graph, it is recommended to use either \code{dnorm} or \code{bayes} method instead.}

\item{ratio.method.M}{A character string indicating the method used to estimate the density ratio associated with M. There are three options: 'bayes', 'dnorm', and 'densratio'.
The default is 'bayes'. The "bayes" method estimates the density ratio \eqn{p(M|...,A=a0)/p(M|...,A=a1)} by rewriting it as \eqn{(p(a0|M,...)/p(a1|M,...))/(p(a0|...)/p(a1|...))}.
Here \eqn{p(a0|M,...)} and \eqn{p(a0|...)} are estimated via linear regression if \code{superlearner.M=F} and via superlearner if \code{superlearner.M=T}.}

\item{dnorm.formula.M}{A list of regression formulas specifying the relationship between M and its Markov pillow when the \code{ratio.method.M="dnorm"}. If not specified, the function will fit a linear regression model M ~ . .
If M is a multivariate variable, the formula should be a list with the names of the variables in M as the names of the list and the regression formula as the values.
For example, if M is a multivariate variable with two components M.1 and M.2, the formula can be specified as list(M.1 = "M.1 ~ A + X", M.2 = "M.2 ~ A + X").
We can also only specify regression for some of the variables in M. For example, if we only want to specify regression for M.1, the formula can be specified as list(M.1 = "M.1 ~ A + X").}

\item{dnorm.formula.L}{A list of regression formulas specifying the relationship between L and its Markov pillow when the \code{ratio.method.L="dnorm"}. If not specified, the function will fit a linear regression model L ~ . .
If L is a multivariate variable, the formula should be a list with the names of the variables in L as the names of the list and the regression formula as the values.
For example, if L is a multivariate variable with two components L.1 and L.2, the formula can be specified as list(L.1 = "L.1 ~ A + X + M", L.2 = "L.2 ~ A + X + I(M^2)").
We can also only specify regression for some of the variables in L. For example, if we only want to specify regression for L.1, the formula can be specified as list(L.1 = "L.1 ~ A + X").}

\item{lib.seq}{A character vector specifying the library of algorithms to be used in the SuperLearner for sequential regression.}

\item{lib.L}{A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with L.}

\item{lib.M}{A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with M.}

\item{lib.Y}{A character vector specifying the library of algorithms to be used in the SuperLearner for outcome regression.}

\item{lib.A}{A character vector specifying the library of algorithms to be used in the SuperLearner for propensity score estimation.}

\item{formulaY}{Regression formula for the outcome regression of Y on it's Markov pillow. The default is 'Y ~ .'.}

\item{formulaA}{Regression formula for the propensity score regression of A on it's Markov pillow. The default is 'A ~ .'.}

\item{linkY_binary}{The link function used for outcome regression of Y on it's Markov pillow when Y is binary and superlearner is not sued. The default is the 'logit' link.}

\item{linkA}{The link function used for propensity score regression of A on it's Markov pillow if superlearner is not used. The default is the 'logit' link.}

\item{n.iter}{The maximum number of iterations for the iterative update of the nuisances in TMLE. The default value is 500.}

\item{cvg.criteria}{A numerical value representing the convergence criteria for the iterative update of the nusiances in TMLE.
If the absolute of the mean of efficient influence function is less than cvg.criteria, the iterative update stops. The default value is 0.01.}

\item{truncate_lower}{The lower bound for truncation of the propensity score. The default is 0, which means no truncation.}

\item{truncate_upper}{The upper bound for truncation of the propensity score. The default is 1, which means no truncation.}

\item{zerodiv.avoid}{A numerical threshold to avoid division by zero in the estimation of the density ratio. The default is 0, which means no threshold.}
}
\value{
Function outputs a list containing TMLE results and onestep results:
\describe{
\item{\code{estimated_psi}}{The estimated parameter of interest: \eqn{E(Y^a)}}
\item{\code{lower.ci}}{Lower bound of the 95\% confidence interval for \code{estimated_psi}}
\item{\code{upper.ci}}{Upper bound of the 95 pct confidence interval for \code{estimated_psi}}
\item{\code{EIF}}{The estimated efficient influence function evaluated at the observed data}
\item{\code{EIF.Y}}{The part of the EIF corresponding to the outcome regression}
\item{\code{EIF.A}}{The part of EIF corresponding to the propensity score regression}
\item{\code{EIF.v}}{The part of EIF corresponding to variables that between treatment and outcome according to the topological order of vertices in the graph.}
\item{\code{p.a1.mpA}}{The estimated propensity score for treatment level 1-a given the Markov pillow of A}
\item{\code{mu.next.A}}{Estimated \eqn{E[v|mp(v)]} for v that comes right after A in topological order}
\item{\code{EDstar}}{The sample mean of the estimated efficient influence function. If convergence is achieved, this should be close to 0 for TMLE estimators.}
.      \item{\code{EDstar.record}}{A vector recording the value of EDstar over iterations.}
\item{\code{iter}}{Number of iterations where convergence is achieved for the iterative update of the mediator density and propensity score.}}
}
\description{
Function for estimating the average counterfactual outcome E(Y(a)) under a nonparametrically saturated model.
}
\details{
In assuming normal distribution. The \code{dnorm} method estimates the mean of the normal distribution by fitting a linear regression model with only linear terms and no interaction terms and the variance of the normal distribution sample variance of the error term resulted from the linear regression model.
In assuming logistic regression, the \code{dnorm} method further assume the logistic regression contains only linear terms and no interaction terms.
}
\examples{
# E(Y(1)) estimation.
NPS.TMLE.a(a=1,data=data_fig_4a, vertices=c('A','M','L','Y','X'),
bi_edges=list(c('A','Y')), di_edges=list(c('X','A'), c('X','M'),
c('X','L'),c('X','Y'), c('M','Y'), c('A','M'), c('A','L'), c('M','L'), c('L','Y')),
treatment='A', outcome='Y', multivariate.variables = list(M=c('M.1','M.2')))
}
