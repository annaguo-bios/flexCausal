% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NPS-TMLE-a.R
\name{NPS.TMLE.a}
\alias{NPS.TMLE.a}
\title{Estimate average counterfactual outcome E(Y(a)).}
\usage{
NPS.TMLE.a(
  a,
  data,
  vertices,
  di_edges,
  bi_edges,
  treatment,
  outcome,
  multivariate.variables = NULL,
  superlearner.seq = F,
  superlearner.Y = F,
  superlearner.A = F,
  superlearner.M = F,
  superlearner.L = F,
  crossfit = F,
  K = 5,
  ratio.method.L = "bayes",
  ratio.method.M = "bayes",
  lib.seq = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.L = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.M = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.Y = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  lib.A = c("SL.glm", "SL.earth", "SL.ranger", "SL.mean"),
  formulaY = "Y ~ .",
  formulaA = "A ~ .",
  linkY_binary = "logit",
  linkA = "logit",
  n.iter = 500,
  cvg.criteria = 0.01,
  truncate_lower = 0,
  truncate_upper = 1
)
}
\arguments{
\item{a}{Treatment level at which the average counterfactual outcome is computed}

\item{data}{A Dataframe contains all the variables listed in vertices parameter}

\item{vertices}{A vector of variable names in the causal graph}

\item{di_edges}{A list of directed edges in the causal graph. For example, \code{di_edges=list(c('A','B'))} means there is a directed edge from vertex A to B.}

\item{bi_edges}{A list of bidirected edges in the causal graph. For example, \code{bi_edges=list(c('A','B'))} means there is a bidirected edge between vertex A and B.}

\item{treatment}{A character string indicating the treatment variable}

\item{outcome}{A character string indicating the outcome variable}

\item{multivariate.variables}{A list of variables that are multivariate in the causal graph. For example, \verb{multivariate.variables=list(M=c('M1,'M2'))} means M is bivariate and the corresponding columns in the dataframe are M1 and M2.}

\item{superlearner.seq}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted when performing sequential regression to estimate the conditional expectations as the nuisances consititute the efficient influence function.}

\item{superlearner.Y}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the outcome regression.}

\item{superlearner.A}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the propensity score.}

\item{superlearner.M}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set M when \code{ratio.method.M="bayes"}.}

\item{superlearner.L}{A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set L when \code{ratio.method.L="bayes"}.}

\item{crossfit}{A logical indicator determines whether crossfitting is adopted for SuperLearner. If crossfit is set to TRUE, the data is split into K folds as specified by the \code{K} parameter.}

\item{K}{An integer specifying the number of folds for crossfitting.}

\item{ratio.method.L}{A character string indicating the method used to estimate the density ratio associated with L.
The default is 'bayes'. The "bayes" method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by rewriting it as \eqn{(p(a0|L,...)/p(a1|L,...))/(p(a0|...)/p(a1|...))}.
Here \eqn{p(a0|L,...)} and \eqn{p(a0|...)} are estimated via linear regression if \code{superlearner.L=F} and via superlearner if \code{superlearner.L=T}.}

\item{ratio.method.M}{A character string indicating the method used to estimate the density ratio associated with M.
The default is 'bayes'. The "bayes" method estimates the density ratio \eqn{p(M|...,A=a0)/p(M|...,A=a1)} by rewriting it as \eqn{(p(a0|M,...)/p(a1|M,...))/(p(a0|...)/p(a1|...))}.
Here \eqn{p(a0|M,...)} and \eqn{p(a0|...)} are estimated via linear regression if \code{superlearner.M=F} and via superlearner if \code{superlearner.M=T}.}

\item{lib.seq}{A character vector specifying the library of algorithms to be used in the SuperLearner for sequential regression.}

\item{lib.L}{A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with L.}

\item{lib.M}{A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with M.}

\item{lib.Y}{A character vector specifying the library of algorithms to be used in the SuperLearner for outcome regression.}

\item{lib.A}{A character vector specifying the library of algorithms to be used in the SuperLearner for propensity score estimation.}

\item{formulaY}{Regression formula for the outcome regression of Y on it's Markov pillow. The default is 'Y ~ .'.}

\item{formulaA}{Regression formula for the propensity score regression of A on it's Markov pillow. The default is 'A ~ .'.}

\item{linkY_binary}{The link function used for outcome regression of Y on it's Markov pillow when Y is binary and superlearner is not sued. The default is the 'logit' link.}

\item{linkA}{The link function used for propensity score regression of A on it's Markov pillow if superlearner is not used. The default is the 'logit' link.}

\item{n.iter}{The maximum number of iterations for the iterative update of the nuisances in TMLE. The default value is 500.}

\item{cvg.criteria}{A numerical value representing the convergence criteria for the iterative update of the nusiances in TMLE.
If the absolute of the mean of efficient influence function is less than cvg.criteria, the iterative update stops. The default value is 0.01.}

\item{truncate_lower}{The lower bound for truncation of the propensity score. The default is 0, which means no truncation.}

\item{truncate_upper}{The upper bound for truncation of the propensity score. The default is 1, which means no truncation.}
}
\value{
Function outputs a list containing TMLE results and onestep results:
\describe{
\item{\code{estimated_psi}}{The estimated parameter of interest: \eqn{E(Y^a)}}
\item{\code{lower.ci}}{Lower bound of the 95\% confidence interval for \code{estimated_psi}}
\item{\code{upper.ci}}{Upper bound of the 95 pct confidence interval for \code{estimated_psi}}
\item{\code{EIF}}{The estimated efficient influence function evaluated at the observed data}
\item{\code{EIF.Y}}{The part of the EIF corresponding to the outcome regression}
\item{\code{EIF.A}}{The part of EIF corresponding to the propensity score regression}
\item{\code{EIF.v}}{The part of EIF corresponding to variables that between treatment and outcome according to the topological order of vertices in the graph.}
\item{\code{p.a1.mpA}}{The estimated propensity score for treatment level 1-a given the Markov pillow of A}
\item{\code{mu.next.A}}{Estimated \eqn{E[v|mp(v)]} for v that comes right after A in topological order}
\item{\code{EDstar}}{The sample mean of the estimated efficient influence function. If convergence is achieved, this should be close to 0 for TMLE estimators.}
.      \item{\code{EDstar.record}}{A vector recording the value of EDstar over iterations.}
\item{\code{iter}}{Number of iterations where convergence is achieved for the iterative update of the mediator density and propensity score.}}
}
\description{
Function for estimating the average counterfactual outcome E(Y(a)) under a nonparametrically saturated model.
}
\examples{
# E(Y(1)) estimation.
NPS.TMLE.a(a=1,data=data_fig_4a, vertices=c('A','M','L','Y','X'),
bi_edges=list(c('A','Y')), di_edges=list(c('X','A'), c('X','M'),
c('X','L'),c('X','Y'), c('M','Y'), c('A','M'), c('A','L'), c('M','L'), c('L','Y')),
treatment='A', outcome='Y', multivariate.variables = list(M=c('M1','M2')))
}
