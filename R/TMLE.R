## Provide onestep and TMLE estimators under nonparametrically saturated model ====
#' Estimate average counterfactual outcome E(Y(a)).
#'
#' Function for estimating the average counterfactual outcome E(Y(a)) under a nonparametrically saturated model.
#' @param a Treatment level or a length two vector specifying treatment levels.
#'          The average counterfactual outcome(s) will be computed at the specified treatment level(s).
#'          If `a` is a single value, the function will return `E(Y(a))`, which is the
#'          average counterfactual outcome under the treatment level specified by `a`.
#'          If `a` is a vector of length two, say `c(value1, value2)`, the function will return
#'          `E(Y(a=value1)) - E(Y(a=value2))`, which is the contrast between the average
#'          counterfactual outcomes under the two specified treatment levels.
#' @param data A Dataframe contains all the variables listed in vertices parameter
#' @param vertices A vector of variable names in the causal graph
#' @param di_edges A list of directed edges in the causal graph. For example, `di_edges=list(c('A','B'))` means there is a directed edge from vertex A to B.
#' @param bi_edges A list of bidirected edges in the causal graph. For example, `bi_edges=list(c('A','B'))` means there is a bidirected edge between vertex A and B.
#' @param multivariate.variables A list of variables that are multivariate in the causal graph. For example, `multivariate.variables=list(M=c('M1,'M2'))` means M is bivariate and the corresponding columns in the dataframe are M1 and M2.
#' @param graph A graph object generated by the `make.graph()` function. User only need to specify either `graph` or `vertices`, `di_edges`, `bi_edges`, and `multivariate.variables`.
#' @param treatment A character string indicating the treatment variable
#' @param outcome A character string indicating the outcome variable
#' @param superlearner.seq A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted when performing sequential regression to estimate the conditional expectations as the nuisances consititute the efficient influence function.
#' @param superlearner.Y A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the outcome regression.
#' @param superlearner.A A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the propensity score.
#' @param superlearner.M A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set M when `ratio.method.M="bayes"`.
#' @param superlearner.L A logical indicator determines whether SuperLearner via the \link[SuperLearner]{SuperLearner} function is adopted for estimating the density ratio for variables in set L when `ratio.method.L="bayes"`.
#' @param crossfit A logical indicator determines whether crossfitting is adopted for SuperLearner. If crossfit is set to TRUE, the data is split into K folds as specified by the `K` parameter.
#' @param K An integer specifying the number of folds for crossfitting.
#' @param ratio.method.L A character string indicating the method used to estimate the density ratio associated with L. There are three options: 'bayes', 'dnorm', and 'densratio'.
#' The default is 'bayes'. The `bayes` method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by rewriting it as \eqn{(p(a0|L,...)/p(a1|L,...))/(p(a0|...)/p(a1|...))}.
#' Here \eqn{p(a0|L,...)} and \eqn{p(a0|...)} are estimated via linear regression if `superlearner.L=F` and via superlearner if `superlearner.L=T`.
#' The `dnorm` method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by assuming that the density of L given A is normal if L is continuous. And assume L|...,A can be modeled via logistic regression if L is binary.
#' The `densratio` method estimates the density ratio \eqn{p(L|...,A=a0)/p(L|...,A=a1)} by using the `densratio` function in the \link[densratio]{densratio} package. The `densratio` method is computationally expensive compared to the other two methods.
#' Therefore, if there is a large number of variables in your graph, it is recommended to use either `dnorm` or `bayes` method instead.
#' @details In assuming normal distribution. The `dnorm` method estimates the mean of the normal distribution by fitting a linear regression model with only linear terms and no interaction terms and the variance of the normal distribution sample variance of the error term resulted from the linear regression model.
#' In assuming logistic regression, the `dnorm` method further assume the logistic regression contains only linear terms and no interaction terms.
#' @param ratio.method.M A character string indicating the method used to estimate the density ratio associated with M. There are three options: 'bayes', 'dnorm', and 'densratio'.
#' The default is 'bayes'. The "bayes" method estimates the density ratio \eqn{p(M|...,A=a0)/p(M|...,A=a1)} by rewriting it as \eqn{(p(a0|M,...)/p(a1|M,...))/(p(a0|...)/p(a1|...))}.
#' Here \eqn{p(a0|M,...)} and \eqn{p(a0|...)} are estimated via linear regression if `superlearner.M=F` and via superlearner if `superlearner.M=T`.
#' @param dnorm.formula.L A list of regression formulas specifying the relationship between L and its Markov pillow when the `ratio.method.L="dnorm"`. If not specified, the function will fit a linear regression model L ~ . .
#' If L is a multivariate variable, the formula should be a list with the names of the variables in L as the names of the list and the regression formula as the values.
#' For example, if L is a multivariate variable with two components L.1 and L.2, the formula can be specified as list(L.1 = "L.1 ~ A + X + M", L.2 = "L.2 ~ A + X + I(M^2)").
#' We can also only specify regression for some of the variables in L. For example, if we only want to specify regression for L.1, the formula can be specified as list(L.1 = "L.1 ~ A + X").
#' @param dnorm.formula.M A list of regression formulas specifying the relationship between M and its Markov pillow when the `ratio.method.M="dnorm"`. If not specified, the function will fit a linear regression model M ~ . .
#' If M is a multivariate variable, the formula should be a list with the names of the variables in M as the names of the list and the regression formula as the values.
#' For example, if M is a multivariate variable with two components M.1 and M.2, the formula can be specified as list(M.1 = "M.1 ~ A + X", M.2 = "M.2 ~ A + X").
#' We can also only specify regression for some of the variables in M. For example, if we only want to specify regression for M.1, the formula can be specified as list(M.1 = "M.1 ~ A + X").
#' @param lib.seq A character vector specifying the library of algorithms to be used in the SuperLearner for sequential regression.
#' @param lib.L A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with L.
#' @param lib.M A character vector specifying the library of algorithms to be used in the SuperLearner for estimating the density ratio associated with M.
#' @param lib.Y A character vector specifying the library of algorithms to be used in the SuperLearner for outcome regression.
#' @param lib.A A character vector specifying the library of algorithms to be used in the SuperLearner for propensity score estimation.
#' @param formulaY Regression formula for the outcome regression of Y on it's Markov pillow. The default is 'Y ~ .'.
#' @param formulaA Regression formula for the propensity score regression of A on it's Markov pillow. The default is 'A ~ .'.
#' @param linkY_binary The link function used for outcome regression of Y on it's Markov pillow when Y is binary and superlearner is not sued. The default is the 'logit' link.
#' @param linkA The link function used for propensity score regression of A on it's Markov pillow if superlearner is not used. The default is the 'logit' link.
#' @param cvg.criteria A numerical value representing the convergence criteria for the iterative update of the nusiances in TMLE.
#' If the absolute of the mean of efficient influence function is less than cvg.criteria, the iterative update stops. The default value is 0.01.
#' @param n.iter The maximum number of iterations for the iterative update of the nuisances in TMLE. The default value is 500.
#' @param truncate_lower The lower bound for truncation of the propensity score. The default is 0, which means no truncation.
#' @param truncate_upper The upper bound for truncation of the propensity score. The default is 1, which means no truncation.
#' @param zerodiv.avoid A numerical threshold to avoid division by zero in the estimation of the density ratio. The default is 0, which means no threshold.
#' @return Function outputs a list containing TMLE results and onestep results:
#' \describe{
#'       \item{\code{estimated_psi}}{The estimated parameter of interest: \eqn{E(Y^a)}}
#'       \item{\code{lower.ci}}{Lower bound of the 95% confidence interval for \code{estimated_psi}}
#'       \item{\code{upper.ci}}{Upper bound of the 95 pct confidence interval for \code{estimated_psi}}
#'       \item{\code{EIF}}{The estimated efficient influence function evaluated at the observed data}
#'       \item{\code{EIF.Y}}{The part of the EIF corresponding to the outcome regression}
#'       \item{\code{EIF.A}}{The part of EIF corresponding to the propensity score regression}
#'       \item{\code{EIF.v}}{The part of EIF corresponding to variables that between treatment and outcome according to the topological order of vertices in the graph.}
#'       \item{\code{p.a1.mpA}}{The estimated propensity score for treatment level 1-a given the Markov pillow of A}
#'       \item{\code{mu.next.A}}{Estimated \eqn{E[v|mp(v)]} for v that comes right after A in topological order}
#'       \item{\code{EDstar}}{The sample mean of the estimated efficient influence function. If convergence is achieved, this should be close to 0 for TMLE estimators.}
#'.      \item{\code{EDstar.record}}{A vector recording the value of EDstar over iterations.}
#'       \item{\code{iter}}{Number of iterations where convergence is achieved for the iterative update of the mediator density and propensity score.}}
#' @examples
#' # E(Y(1)) estimation.
#' ADMGtmle(a=1,data=data_fig_4a, vertices=c('A','M','L','Y','X'),
#' bi_edges=list(c('A','Y')), di_edges=list(c('X','A'), c('X','M'),
#' c('X','L'),c('X','Y'), c('M','Y'), c('A','M'), c('A','L'), c('M','L'), c('L','Y')),
#' treatment='A', outcome='Y', multivariate.variables = list(M=c('M.1','M.2')))
#' @importFrom dplyr %>% mutate select
#' @importFrom MASS mvrnorm
#' @importFrom SuperLearner CV.SuperLearner SuperLearner
#' @importFrom mvtnorm dmvnorm
#' @importFrom densratio densratio
#' @importFrom utils combn
#' @importFrom stats rnorm runif rbinom dnorm dbinom binomial gaussian predict glm as.formula qlogis plogis lm coef cov sd
#' @export
#'
#'
ADMGtmle <- function(a=NULL,data=NULL,vertices=NULL, di_edges=NULL, bi_edges=NULL, treatment=NULL, outcome=NULL, multivariate.variables=NULL, graph=NULL,
                 superlearner.seq = F, # whether run superlearner for sequential regression
                 superlearner.Y=F, # whether run superlearner for outcome regression
                 superlearner.A=F, # whether run superlearner for propensity score
                 superlearner.M=F, # whether run superlearner for estimating densratio for M using bayes method
                 superlearner.L=F, # whether run superlearner for estimating densratio for L using bayes method
                 crossfit=F, K=5,
                 ratio.method.L="bayes", # method for estimating the density ratio associated with M
                 ratio.method.M="bayes", # method for estimating the density ratio associated with L
                 dnorm.formula.L=NULL, # formula for the density ratio associated with L
                 dnorm.formula.M=NULL, # formula for the density ratio associated with M
                 lib.seq = c("SL.glm","SL.earth","SL.ranger","SL.mean"), # superlearner library for sequential regression
                 lib.L = c("SL.glm","SL.earth","SL.ranger","SL.mean"), # superlearner library for density ratio estimation via bayes rule for variables in L
                 lib.M = c("SL.glm","SL.earth","SL.ranger","SL.mean"), # superlearner library for density ratio estimation via bayes rule for variables in M
                 lib.Y = c("SL.glm","SL.earth","SL.ranger","SL.mean"), # superlearner library for outcome regression
                 lib.A = c("SL.glm","SL.earth","SL.ranger","SL.mean"), # superlearner library for propensity score
                 formulaY="Y ~ .", formulaA="A ~ .", # regression formula for outcome regression and propensity score if superlearner is not used
                 linkY_binary="logit", linkA="logit", # link function for outcome regression and propensity score if superlearner is not used
                 n.iter=500, cvg.criteria=0.01,
                 truncate_lower=0, truncate_upper=1, zerodiv.avoid=0){


  # make a graph object if it's not provided
  if (is.null(graph)){ graph <- make.graph(vertices=vertices, bi_edges=bi_edges, di_edges=di_edges, multivariate.variables=multivariate.variables)}


  #####################################################
  # Fixable vs Primal fixable
  #####################################################


  if (suppressMessages(is.fix(graph, treatment))){ # if the graph is fixable

    message("The treatment is fixable. Estimation provided via backdoor adjustment.")


    np.out <- .call_backdoor(a = a, data = data, vertices = vertices,
                             di_edges = di_edges, bi_edges = bi_edges, treatment = treatment, outcome = outcome,
                             multivariate.variables = multivariate.variables, graph = graph,

                             superlearner.Y = superlearner.Y, # whether run superlearner for outcome regression
                             superlearner.A = superlearner.A, # whether run superlearner for propensity score

                             crossfit = crossfit, K = K,

                             lib.Y = lib.Y, # superlearner library for outcome regression
                             lib.A = lib.A, # superlearner library for propensity score

                             formulaY = formulaY, formulaA = formulaA, # regression formula for outcome regression and propensity score if superlearner is not used
                             linkY_binary = linkY_binary, linkA = linkA, # link function for outcome regression and propensity score if superlearner is not used

                             truncate_lower = truncate_lower, truncate_upper = truncate_upper)

    return(np.out)


  }else if (!suppressMessages(is.p.fix(graph, treatment))){ # the graph is not fixable: if the graph is primal fixable




    stop("The treatment is not fixable nor primal-fixable. The treatment effect may or may not be identified. Further investigation is needed.") # the graph is not primal fixable



  }else{ # the graph is not fixable: the graph is primal fixable


    np.out <- .call_nps(a = a, data = data, vertices = vertices,
                        di_edges = di_edges, bi_edges = bi_edges, treatment = treatment, outcome = outcome,
                        multivariate.variables = multivariate.variables, graph = graph,

                        superlearner.seq = superlearner.seq, # whether run superlearner for sequential regression
                        superlearner.Y = superlearner.Y, # whether run superlearner for outcome regression
                        superlearner.A = superlearner.A, # whether run superlearner for propensity score
                        superlearner.M = superlearner.M, # whether run superlearner for estimating densratio for M using bayes method
                        superlearner.L = superlearner.L, # whether run superlearner for estimating densratio for L using bayes method

                        crossfit = crossfit, K = K,

                        ratio.method.L = ratio.method.L, # method for estimating the density ratio associated with M
                        ratio.method.M = ratio.method.M, # method for estimating the density ratio associated with L

                        dnorm.formula.L = dnorm.formula.L, # formula for the density ratio associated with L
                        dnorm.formula.M = dnorm.formula.M, # formula for the density ratio associated with M

                        lib.seq = lib.seq, # superlearner library for sequential regression
                        lib.L = lib.L, # superlearner library for density ratio estimation via bayes rule for variables in L
                        lib.M = lib.M, # superlearner library for density ratio estimation via bayes rule for variables in M
                        lib.Y = lib.Y, # superlearner library for outcome regression
                        lib.A = lib.A, # superlearner library for propensity score

                        formulaY = formulaY, formulaA = formulaA, # regression formula for outcome regression and propensity score if superlearner is not used
                        linkY_binary = linkY_binary, linkA = linkA, # link function for outcome regression and propensity score if superlearner is not used

                        n.iter = n.iter, cvg.criteria = cvg.criteria,
                        truncate_lower = truncate_lower, truncate_upper = truncate_upper, zerodiv.avoid=zerodiv.avoid)



  } # end of if else for fix, p-fix







  #####################################################
  # NPS and semi-parametric model
  #####################################################

  if (suppressMessages(is.np.saturated(graph))){

    message("\n The graph is nonparametrically saturated. The nonparametric TMLE and one-step estimator results are provided, which are in theory the most efficient estimators.")

  }else{

    message("\n The graph is NOT nonparametrically saturated. Note that there may be more efficient estimators.")

  }



return(np.out)







} # end of ADMGtmle function


